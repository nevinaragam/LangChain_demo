{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7492e65e-b0e4-4962-bef9-be7a0966e636",
   "metadata": {},
   "source": [
    "# 1. Installing libraries and connecting to LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee4f3f5-528f-4659-8768-b603db0a426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b0d823-6d70-44e1-a93b-9a6ef28cafcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935e3238-9344-4d5e-b673-c9d0035c082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_claude3 = ChatAnthropic(model='claude-3-opus-20240229')  # $15/1M input, $75/1M output (8/29/2024)\n",
    "llm_claude3 = ChatAnthropic(model='claude-3-5-sonnet-20240620')  # $3/1M input, $15/1M output (8/29/2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7df419-f8eb-49df-b1b3-12795ccbcc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_claude3.invoke(\"What is LangChain?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d704ba0f-a6eb-4fb0-b0bc-1a1d45522879",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=\"\"\"\n",
    "You explain things to people like they are five years old.\n",
    "\"\"\"\n",
    "user_prompt=\"\"\"\n",
    "What is LangChain?\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(content=user_prompt),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72972581-a4b7-482a-a92c-b79d716a1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_claude3.invoke(messages)\n",
    "answer = textwrap.fill(response.content, width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00debbd-1af8-48ad-a134-dc52ac6e9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b707b1-da73-4ec8-b8cf-134548cc8cd2",
   "metadata": {},
   "source": [
    "# 2. Chains, Prompts and Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8f77a5-d185-446c-a0c5-4b0b55311895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cbb381-18c0-433f-b403-7f19233f8a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple prompt template\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant that explains AI topics. Given the following input:\n",
    "{topic}\n",
    "Provide an explanation of the given topic.\n",
    "\"\"\"\n",
    "\n",
    "# Create ther prompt from the prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=prompt_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d7ce1f-6feb-4fe3-b5c8-a2a6c904adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the chain using the pipe operator \"|\", more on this later...\n",
    "chain = prompt | llm_claude3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ddbb71-88fb-410e-afa9-5b75d7f220a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"topic\": \"What is LangChain?\"}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e508eebf-de3c-46f7-bb8f-796729a2b21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d646828-9907-4b67-a192-b37e280a6f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    \"https://www.youtube.com/shorts/xS55duPS-Pw\",\n",
    "    add_video_info=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fed48f-7335-43ba-a98a-8490974afb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the video transcript as documents\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cf9bd5-6eff-4a7f-b98a-a6be7ebf74d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3965b1-60cf-42f4-9a01-cbb22761fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9049dcc4-d9c7-4532-bc38-3e6d60c80b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now use the transcript in a chain\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant that explains YT videos. Given the following video trasncript:\n",
    "{video_transcript}\n",
    "Give a summary.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"video_transcript\"],\n",
    "    template=prompt_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c2da16-20f5-4738-8a3d-370dfd94d4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm_claude3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f686049-389b-4ce0-b9e3-cac667a5c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"video_transcript\": docs}).content\n",
    "# Note that we can just feed the chain the docs without extracting the content as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914cb9bf-1b3c-4215-9b0f-02bc65a39954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919eb84d-3cff-4015-b006-5f81075c843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The creacreate_stuff_documents_chain takes a list of docs and formats them all into a prompt\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant that explains AI topics. Given the following context:\n",
    "{context}\n",
    "Summarize what RAG can do.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "chain = create_stuff_documents_chain(llm_claude3, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbd3395-dace-4801-9376-22dffece8b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"context\": docs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6ece3b-d29e-435b-b6a3-218c6d315d4a",
   "metadata": {},
   "source": [
    "# 3. LCEL & Runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db6ff37-d5d3-4221-94b7-990f5439de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f3c3d4-dfb6-4990-9821-591269b5748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_prompt_template = \"\"\"\n",
    "You are a helpful assistant that summarizes AI concepts:\n",
    "{context}\n",
    "Summarize the context\n",
    "\"\"\"\n",
    "\n",
    "summarize_prompt = PromptTemplate.from_template(summarize_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d323162-ede7-4b99-8bbd-4cd29d0019e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c77abf-0004-4e58-adfe-498c32652eb0",
   "metadata": {},
   "source": [
    "## Create a chain with the \"|\" operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034f7766-01c2-48a5-a0a8-36a0184f9990",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = summarize_prompt | llm_claude3 | output_parser\n",
    "\n",
    "chain.invoke({\"context\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d1b192-ce3c-47d5-8cf3-183e5b102982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the type of the chain\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbda226-34e3-4e72-972e-ea1280822301",
   "metadata": {},
   "source": [
    "## Using a RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89390506-27c2-47f2-a141-cc948875c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673d716f-f72f-4a03-b943-19a8ed5c2d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_chain = summarize_prompt | llm_claude3 | output_parser\n",
    "\n",
    "# Define a custom lambda function and wrap it in RunnableLambda\n",
    "length_lambda = RunnableLambda(lambda summary: f\"Summary length: {len(summary)} characters\")\n",
    "\n",
    "lambda_chain = summarize_chain | length_lambda\n",
    "\n",
    "lambda_chain.invoke({\"context\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4aa4f-40a3-432b-8e7b-52c509437f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(lambda_chain.steps[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eb6904-990e-44e8-bfd9-9fa1553d0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(lambda_chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa82ddf5-9595-44ca-811f-c36e332dac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function in a chain without wrapping in RunnableLambda\n",
    "chain_with_function = summarize_chain | (lambda summary: f\"Summary length: {len(summary)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6efccb-9ca1-4337-8a80-613fd9acccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(chain_with_function.steps[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73978bb5-33a2-4c16-a194-b289e295bfe7",
   "metadata": {},
   "source": [
    "## RunnablePassthrough as a placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccde387-711a-4cf2-bf2b-661c6c1dac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43179715-a17f-4c74-930b-c82892d098e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_chain = summarize_prompt | llm_claude3 | output_parser\n",
    "\n",
    "# Create a RunnablePassthrough instance\n",
    "passthrough = RunnablePassthrough()\n",
    "\n",
    "placeholder_chain = summarize_chain | passthrough | length_lambda\n",
    "\n",
    "placeholder_chain.invoke({\"context\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b6f925-763d-4f3e-a573-4e460dbab6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(placeholder_chain.steps[-1]))\n",
    "print(type(placeholder_chain.steps[-2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e18cb4c-f5ff-418e-a639-b91d5a470543",
   "metadata": {},
   "source": [
    "### \"Passing data through without changing it like this is typically used with RunnableParallel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6011776-6308-4a22-a810-92deae2cf269",
   "metadata": {},
   "source": [
    "## RunnablePassthrough for assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2370b164-8aa7-47d6-b765-d7b42d7a6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom lambda function to wrap the summary in a dictionary\n",
    "wrap_summary_lambda = RunnableLambda(lambda summary: {\"summary\": summary})\n",
    "\n",
    "# Create a RunnablePassthrough instance that assigns additional information\n",
    "assign_passthrough = RunnablePassthrough.assign(length=lambda x: len(x[\"summary\"]))\n",
    "\n",
    "# Create the summarization chain\n",
    "summarize_chain = summarize_prompt | llm_claude3 | output_parser | wrap_summary_lambda\n",
    "\n",
    "# Create the full chain combining summmarization and assign_passthrough\n",
    "assign_chain = summarize_chain | assign_passthrough\n",
    "\n",
    "assign_chain.invoke({\"context\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5c33f6-9a14-401d-b710-ff520756ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(assign_chain.steps[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ccf03-658c-4edb-8a0f-9076865933ae",
   "metadata": {},
   "source": [
    "## Using RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55489d2f-f263-4487-9d78-be67c4a8b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d87398-d836-4305-bee9-075d0fa8a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_chain = summarize_prompt | llm_claude3 | output_parser\n",
    "\n",
    "# Create a RunnablePassthrough instance\n",
    "parallell_runnable = RunnableParallel(\n",
    "    summary=lambda x: x,  # Passes the summary as is\n",
    "    length=lambda x: len(x)  # Calculates the length of the summary    \n",
    ")\n",
    "\n",
    "parallell_chain = summarize_chain | parallell_runnable\n",
    "\n",
    "parallell_chain.invoke({\"context\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b99bf76-1c02-49ae-8955-d6f59371b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(parallell_chain.steps[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c510859-19d2-418c-9832-9061cd7975ae",
   "metadata": {},
   "source": [
    "# Splitters and Retrievers\n",
    "\n",
    "We split our data into smaller pieces and load them into Redis as an index database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4711482-2c79-4f25-bc9c-548910b8fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    \"https://www.youtube.com/watch?v=AOEGOhkGtjI\",\n",
    "    add_video_info=False,\n",
    ")\n",
    "\n",
    "# load the video transcript as documents\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b584ed1-f148-4c4c-91af-beeceed9541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6696cbab-3d89-4abb-9653-16eefdc3c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4348393-9dd9-48bb-a330-447f3a8820d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_split = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6e681d-c924-414f-8584-f8f37f140a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7524853-30ac-441b-b3ee-2ea81fd296d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined in env file\n",
    "REDIS_HOST = \"localhost\"\n",
    "REDIS_PORT = 6379\n",
    "# REDIS_USER = os.environ.get(\"REDIS_USER\")\n",
    "# REDIS_PASSWORD = os.environ.get(\"REDIS_PASSWORD\")\n",
    "# REDIS_URL = f\"redis://{REDIS_USER}:{REDIS_PASSWORD}@localhost:6379\"\n",
    "REDIS_URL = f\"redis://localhost:6379\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf9f67f-f1a8-4739-ba02-541aab142780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = redis.Redis(\n",
    "#     host=REDIS_HOST,\n",
    "#     port=REDIS_PORT,\n",
    "#     username=REDIS_USER,\n",
    "#     password=REDIS_PASSWORD,\n",
    "# )\n",
    "\n",
    "r = redis.Redis(\n",
    "    host=REDIS_HOST,\n",
    "    port=REDIS_PORT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e84c0-f49c-4c65-ab19-b0b7a5da8fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf775d5-a9d4-46ad-a13b-8c9370d2fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.flushdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de27973-a747-4e8e-9274-038462910cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8959b56-ee83-4a3c-b5b4-b45baf1d6be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf390a0-0e31-44e6-89c7-effda1965dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3900a52b-4775-450a-8bdc-623cbda1057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rds = Redis.from_documents(\n",
    "    docs_split,\n",
    "    embeddings,\n",
    "    redis_url=REDIS_URL,\n",
    "    index_name=\"youtube\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c6d7a9-3e4b-45d9-8932-0b99c6daaf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rds.index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe18090d-30b5-4579-afb7-5926d961f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = rds.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2633b429-98dd-4e1f-85d0-fa6370b39262",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"data analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357a911c-10c4-4553-b7ec-0c4e0f637297",
   "metadata": {},
   "source": [
    "# 5. Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0dc67-7a1c-4bcf-b606-a9a554b6bba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a755ca2-a306-4a48-a037-5e738bfd80a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5673d63-fca8-4498-ac7f-64d8d278d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5cb14-4752-434c-b320-3072ac6e1524",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff504fc7-297d-4771-af4d-2b6dfcffb1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": (lambda x: x[\"question\"]) | retriever,\n",
    "     \"question\": (lambda x: x[\"question\"])}\n",
    "    | prompt\n",
    "    | llm_claude3\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcda473b-64c1-476e-99b7-7041042e25ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = chain.invoke({\"question\": \"What can you do with Llama 3?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a59cbc3-4f1d-4971-9fdb-187d382c8112",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62070f6-1d03-4abf-9e2e-c2de968a5240",
   "metadata": {},
   "source": [
    "# 6. Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ea494-b0da-4dad-8939-5c9ff94fa674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import YouTubeSearchTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac208cdd-dcc4-4235-9430-bf71ca0b08a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_tool = YouTubeSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9426aad-1a94-4f8e-bef2-5a74fb2b2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_tool.run(\"Rabbitmetrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc16c50-deaf-4a36-9778-2c6bcde47600",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm_claude3.bind_tools([youtube_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c497cbb-6154-4099-9e82-cd52a5457c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = llm_with_tools.invoke(\"Rabbitmetrics YT videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a3414-9811-4d7a-b014-b2bec599b182",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473b68dd-5d2e-45b6-a4de-c4322f39b753",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc21bace-69dc-4269-b99c-d852a1272b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = llm_with_tools | (lambda x: x.tool_calls[0][\"args\"][\"query\"]) | youtube_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7823e3b5-e875-498f-8a70-43ef2d0a8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"Find some Rabbitmetrics videos on langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce7747b-bc9e-452f-a1fc-aa1abd788492",
   "metadata": {},
   "source": [
    "# 7. Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ad82f-6acc-4f34-bd8a-9cf1122a4877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2b0ce7-ac07-4bb2-8867-24d0baf5c547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55b8873-9df8-439f-895b-c2f0247264df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f365bb-c44a-4f42-81a2-f5af19579cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [youtube_tool]\n",
    "\n",
    "agent = create_tool_calling_agent(llm_claude3, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647e414-1c55-420e-8a31-00f69761c1df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Find some MLOps YT videos\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78c4645-d599-4cf5-8d19-53b4e0a3cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_mlops_videos():\n",
    "    try:\n",
    "        result = agent_executor.invoke(\n",
    "            {\n",
    "                \"input\": \"Find some MLOps YT videos\"\n",
    "            }\n",
    "        )\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"\\n\\nAn error occurred and we're consciously ignoring it:\\n\\n {str(e)}\"\n",
    "\n",
    "# Execute the search and print the result\n",
    "result = search_mlops_videos()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3174cb34-fef5-4765-b1bf-f8ae552e9d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d98e006-8644-4101-8e72-ac90209dccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def transcribe_video(video_url: str) -> str:\n",
    "    \"Extract transcript from YT video\"\n",
    "    loader = YoutubeLoader.from_youtube_url(\n",
    "        video_url, add_video_info=False\n",
    "    )\n",
    "    docs=loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86e34b7-73b7-4d33-8e96-52519e3f88f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [youtube_tool, transcribe_video]\n",
    "\n",
    "agent = create_tool_calling_agent(llm_claude3, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c713f-bad6-415a-aa6a-f48b350b453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question_with_youtube(input_question: str):\n",
    "    try:\n",
    "        result = agent_executor.invoke(\n",
    "            {\n",
    "                \"input\": input_question\n",
    "            }\n",
    "        )\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"\\n\\nAn error occurred and we're consciously ignoring it:\\n\\n {str(e)}\"\n",
    "\n",
    "# Execute the search and print the result\n",
    "result = answer_question_with_youtube(\"What is MLOps?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf61fd5-a1de-483d-a9d4-c4725ad2ce8c",
   "metadata": {},
   "source": [
    "# What would a youtube tutorial be without bugs?\n",
    "\n",
    "Unfortunately, we cannot complete the tutorial as presented due to [a bug in AgentExecutors](https://github.com/langchain-ai/langchain/issues/24621).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
